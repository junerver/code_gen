# 部署说明

<cite>
**本文档引用的文件**  
- [nuxt.config.ts](file://nuxt.config.ts)
- [package.json](file://package.json)
- [README.md](file://README.md)
- [server/api/chat.post.ts](file://server/api/chat.post.ts)
- [server/utils/model.ts](file://server/utils/model.ts)
</cite>

## 目录
1. [项目构建与预览](#项目构建与预览)  
2. [输出目录结构](#输出目录结构)  
3. [静态部署配置](#静态部署配置)  
4. [环境变量与敏感信息管理](#环境变量与敏感信息管理)  
5. [API服务端逻辑](#api服务端逻辑)  
6. [部署建议与最佳实践](#部署建议与最佳实践)

## 项目构建与预览

本项目基于 Nuxt 4 构建，采用静态生成（Static Site Generation, SSG）模式。根据 `nuxt.config.ts` 文件中的配置，`ssr: false` 表明应用在构建时将生成静态 HTML 文件，适用于部署在任意静态服务器上。

通过 `package.json` 中定义的脚本可执行构建与预览操作：

- **开发服务器**：`pnpm dev -o` 启动本地开发环境，监听 `http://localhost:3000`
- **生产构建**：`pnpm build` 执行构建，生成静态资源
- **本地预览**：`pnpm preview` 启动本地服务器预览生产构建结果

```bash
# 安装依赖
pnpm install

# 开发模式
pnpm dev -o

# 构建生产资源
pnpm build

# 预览构建结果
pnpm preview
```

构建完成后，可通过 `nuxt preview` 命令在本地验证输出内容是否符合预期，确保路由、样式和交互正常。

**Section sources**
- [nuxt.config.ts](file://nuxt.config.ts#L0-L10)
- [package.json](file://package.json#L5-L14)
- [README.md](file://README.md#L1-L37)

## 输出目录结构

执行 `nuxt build` 命令后，Nuxt 会生成 `.output` 目录，其核心结构如下：

```
.output/
├── public/           # 静态资源（来自 /public 目录）
│   └── robots.txt
├── server/           # 服务端入口（SSR 模式下存在，本项目为 SSG，此目录可能为空或仅含 API）
│   └── index.mjs
└── dist/             # 浏览器可访问的静态文件（HTML、JS、CSS）
    ├── _nuxt/        # Nuxt 框架资源（打包后的 JS/CSS）
    ├── index.html    # 首页
    └── chat/         # 路由页面
        └── index.html
```

由于 `ssr: false`，`.output/dist` 目录下的所有页面均为预渲染的静态 HTML 文件，可直接由 Nginx、Netlify、Vercel 等静态服务器提供服务。

**Section sources**
- [nuxt.config.ts](file://nuxt.config.ts#L0-L10)

## 静态部署配置

### Nginx 部署

将 `.output/dist` 目录内容部署至 Nginx 的 web root 目录，并配置如下：

```nginx
server {
    listen 80;
    server_name your-domain.com;
    root /path/to/.output/dist;
    index index.html;

    location / {
        try_files $uri $uri/ /index.html;
    }
}
```

`try_files` 指令确保前端路由（如 `/chat`）能正确回退到 `index.html`，由客户端路由处理。

### Vercel / Netlify 部署

对于 Vercel 或 Netlify，只需将构建命令设为 `pnpm build`，输出目录设为 `.output/dist`。平台将自动识别并部署静态文件。

**注意**：若使用 Vercel 且希望启用边缘函数或 SSR，需修改 `nuxt.config.ts` 中的 `ssr: true` 并配置 `nitro` 构建选项，但当前项目为纯静态模式。

**Section sources**
- [nuxt.config.ts](file://nuxt.config.ts#L0-L10)
- [package.json](file://package.json#L8-L10)

## 环境变量与敏感信息管理

项目通过 `runtimeConfig` 管理运行时配置，尤其适用于 API 密钥等敏感信息。在 `nuxt.config.ts` 中定义：

```ts
runtimeConfig: {
  siliconFlowApiUrl: '',
  siliconFlowApiKey: '',
}
```

这些变量**仅在服务端可用**，不会暴露给客户端。在服务端代码中通过 `useRuntimeConfig()` 访问：

```ts
// server/utils/model.ts
import { useRuntimeConfig } from '#app';

const config = useRuntimeConfig();
const model = siliconflow('model-name', {
  baseURL: config.siliconFlowApiUrl,
  apiKey: config.siliconFlowApiKey,
});
```

### 部署时配置环境变量

在部署环境中，应通过环境变量注入敏感信息：

- **Vercel**: 在项目设置中添加 `NUXT_SILICON_FLOW_API_URL` 和 `NUXT_SILICON_FLOW_API_KEY`
- **Netlify**: 在 `netlify.toml` 中设置或在 UI 中配置环境变量
- **自托管 Node 服务器**: 使用 `.env` 文件或系统环境变量

Nuxt 会自动将前缀为 `NUXT_` 的环境变量映射到 `runtimeConfig`。

**Section sources**
- [nuxt.config.ts](file://nuxt.config.ts#L7-L10)
- [server/utils/model.ts](file://server/utils/model.ts#L29-L30)

## API服务端逻辑

尽管项目为静态生成（`ssr: false`），但 `server/api/` 目录下仍存在 API 路由，表明其可通过 Nitro Server 处理动态请求。

```ts
// server/api/chat.post.ts
export default defineLazyEventHandler(async () => {
  return defineEventHandler(async (event) => {
    const { messages } = await readBody(event);
    const result = streamText({
      model: siliconflow('Qwen/Qwen3-Coder-30B-A3B-Instruct'),
      system: templateGenPrompt(),
      messages,
    });
    return result.toUIMessageStreamResponse();
  });
});
```

该 API 提供 `/api/chat` 端点，接收消息流并返回 AI 响应流。在部署时：

- **静态平台（Netlify/Vercel）**：需确保平台支持 Serverless Functions，API 将自动部署为函数。
- **自托管**：需使用 `node .output/server/index.mjs` 启动 Node 服务，并配合 PM2 进行进程管理。

```bash
# 启动服务端
node .output/server/index.mjs
```

**Section sources**
- [server/api/chat.post.ts](file://server/api/chat.post.ts#L0-L25)
- [server/utils/model.ts](file://server/utils/model.ts#L29-L30)

## 部署建议与最佳实践

### 缓存策略
- **静态资源**：在 CDN 上设置长期缓存（如 1 年），利用内容哈希确保更新。
- **API 响应**：对 `/api/chat` 等流式响应，建议不缓存或使用短时缓存。

### CDN 集成
将 `.output/dist` 部署至 CDN（如 Cloudflare、AWS CloudFront），提升全球访问速度。确保 CDN 配置支持：
- `text/event-stream` MIME 类型（用于 AI 流式响应）
- WebSocket 或长连接（如需）

### 进程管理（Node.js 部署）
若采用 Node.js 服务器部署 API，建议使用 PM2：

```bash
# 安装 PM2
npm install -g pm2

# 启动服务
pm2 start .output/server/index.mjs --name "ai-app"

# 开机自启
pm2 startup
pm2 save
```

### 反向代理配置
使用 Nginx 作为反向代理，将 `/api/*` 转发至 Node 服务：

```nginx
location /api/ {
    proxy_pass http://localhost:3000;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection 'upgrade';
    proxy_set_header Host $host;
    proxy_cache_bypass $http_upgrade;
}
```

此配置支持 WebSocket 和流式传输，确保 AI 响应实时推送。

**Section sources**
- [server/api/chat.post.ts](file://server/api/chat.post.ts#L0-L25)
- [package.json](file://package.json#L5-L14)